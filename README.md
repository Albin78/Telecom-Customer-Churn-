# ğŸ§  Customer Churn Prediction System


## ğŸ“˜ Overview

This project is an end-to-end Customer Churn Prediction System designed to predict whether a customer is likely to churn (leave) or stay with the service.
It includes complete stages of a real-world ML workflow â€” from data ingestion, feature engineering, and model training to evaluation, artifact saving, and deployment via Streamlit.

The primary objective is to help businesses identify potential churners and take proactive measures for retention.

âš™ï¸ Project Structure


Customer Churn/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ predict_app.py        # Streamlit UI logic
â”‚   â””â”€â”€ run_app.py            # Runs Streamlit app
â”œâ”€â”€ dataset/
|   â”œâ”€â”€ feature_engineered_data.csv        
â”‚   â””â”€â”€ raw_dataset.csv
|  
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA1.ipynb            # Initial exploration
â”‚   â”œâ”€â”€ EDA2.ipynb            # Feature analysis & visualization
â”‚   â”œâ”€â”€ EDA3.ipynb            # Advanced EDA and correlations
â”‚   â”œâ”€â”€ LR_model.ipynb         # Logistic Regression experiments
â”‚   â””â”€â”€ Tree_model.ipynb       # Decision tree and LightGBM modeling
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ LGBM.py               # LightGBM training with CV folds & Optuna tuning
â”‚   â”œâ”€â”€ metrics.py            # Performance evaluation metrics
â”‚   â””â”€â”€ model.py              # Logistic Regression 
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ data_split.py         # Train-test splitting logic
â”‚   â”œâ”€â”€ ingest_clean.py       # Data ingestion, cleaning, and feature engineering
â”‚   â””â”€â”€ preprocess.py         # Additional preprocessing utilities
â”‚
â”œâ”€â”€ predict/
â”‚   â”œâ”€â”€ pipeline.py           # Runs complete pipeline 
â”‚   â””â”€â”€ predict_model.py      # Loads saved model + threshold for predictions
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ final_estimator.pkl       # LightGBM model
â”‚   â”œâ”€â”€ estimator_metadata.json   # Metadata:  best iteration, params
â”‚   |â”€â”€ final_threshold.json      # threshold
â”‚    â””â”€â”€ training_meta.json        # training metadata: features, categories
â”‚   
â”œâ”€â”€ requirements.txt          # All dependencies
â””â”€â”€ README.md                 # Project documentation


ğŸš€ Key Features

âœ… Complete ML Workflow â€” Data ingestion â†’ cleaning â†’ feature engineering â†’ model training â†’ evaluation
âœ… Cross-validation (CV) + Optuna â€” For robust and optimized LightGBM model performance
âœ… Artifact Management â€” Model and metadata saving for reproducibility
âœ… Metrics Module â€” Includes accuracy, precision, recall, F1, AUC, and threshold tuning
âœ… Interactive Streamlit UI â€” For real-time churn predictions
âœ… Modular Design â€” Each component (data, model, prediction, UI) is isolated for scalability

ğŸ§© Model Used

The project implements multiple models (Logistic Regression, Random Forest, LightGBM).
After extensive evaluation, LightGBM was chosen as the final model because it consistently outperformed others in metrics like:

Higher AUC and Average Precision

Faster training time

Better handling of feature interactions

ğŸ§° Installation & Setup

## 1ï¸âƒ£ Clone the repository
git clone https://github.com/Albin78/Telecom-Customer-Churn-.git
cd customer-churn-prediction

## 2ï¸âƒ£ Create & activate a virtual environment
python -m venv .venv

## Activate environment

### On Windows:
.venv\Scripts\activate

### On macOS/Linux:
source .venv/bin/activate

## 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ§ª Running the Pipeline
â–¶ï¸ Run the full training pipeline

This command runs ingestion, cleaning, feature engineering, cross-validation, and model fitting.

python -m predict.pipeline


Artifacts such as the final model and metadata will be saved in the artifacts/ directory.

ğŸ¯ Making Predictions
Using Python


ğŸ–¥ï¸ Launch the Streamlit App
Run Command
cd app
streamlit run predict_app.py


The app provides an interactive interface for entering customer details and viewing predictions visually.

ğŸ¨ Streamlit UI Highlights

Dark blue background theme with a soft overlay

Background image for visual appeal

Styled input components and buttons


Confidence percentage display

Error-handling for model loading and prediction issues

ğŸ“Š Evaluation & Metrics

Performance metrics are implemented in models/metrics.py including:

Accuracy

Precision / Recall / F1

ROC-AUC

Confusion Matrix

Threshold tuning logic (for classification decision boundary optimization)

The final LightGBM model achieved strong performance, outperforming both Logistic Regression and Random Forest models.

ğŸ”® Future Enhancements

ğŸ§¾ More Data Collection: Expanding the dataset for better generalization

ğŸ§  Feature Enrichment: Incorporate behavioral or transactional features

ğŸ” Explainability: Add SHAP-based model interpretability

â˜ï¸ Deployment: Host the model on cloud platforms (AWS, GCP, or Azure)

ğŸ“ˆ MLOps Integration: Automate the workflow using ZenML or MLflow

ğŸ’¬ RAG or LLM Integration: For customer retention insights or intelligent assistant modules


## âš ï¸ Limitations

The current model is limited by the available dataset size and diversity.

May show bias towards certain categories if data imbalance exists.

The threshold tuning may need re-evaluation with new data.

The Streamlit app currently supports only single-record predictions (batch predictions can be added later).